<!DOCTYPE html>
<!--
 * Copyright (C) 2019-2023 Yahweasel and contributors
 *
 * Permission to use, copy, modify, and/or distribute this software for any
 * purpose with or without fee is hereby granted.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
 * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
 * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
 * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
-->
<html>
  <head>
    <meta charset="utf-8" />
    <title>ProRes Software Decoder (Using Filters)</title>
    <style>
      body {
        margin: 0px;
        background-color: black;
        color: white;
      }
      canvas {
        background: repeating-conic-gradient(#808080 0% 25%, white 0% 50%) 50% /
          40px 40px;
      }
    </style>
  </head>
  <body>
    <script type="text/javascript">
      async function fetchFile(url) {
        const response = await fetch(url);
        if (!response.ok) {
          throw new Error("Network response was not ok " + response.statusText);
        }
        const blob = await response.blob();
        return blob;
      }
      (async function () {
        try {
          const version = "4.4.9";

          const dce = document.createElement.bind(document);
          const main = dce("div");
          document.body.appendChild(main);

          const variant = await new Promise((res) => {
            const label = dce("label");
            label.innerHTML = "Variant:&nbsp;";
            label.htmlFor = "variant";
            main.appendChild(label);
            const vbox = dce("input");
            vbox.type = "text";

            vbox.id = "variant";
            const urlParams = new URLSearchParams(window.location.search);

            vbox.value = "descript-p3";
            main.appendChild(vbox);
            const ok = dce("button");
            ok.innerHTML = "Load";
            main.appendChild(ok);

            vbox.focus();
            vbox.select();

            vbox.onkeypress = (ev) => {
              if (ev.key === "Enter") res(vbox.value);
            };
            ok.onclick = (ev) => {
              res(vbox.value);
            };
            res(vbox.value);
          });
          main.innerHTML = "Loading...";

          // Load libav.js
          LibAV = { base: "../dist" };
          await new Promise((res) => {
            const scr = dce("script");
            scr.src = `../dist/libav-${version}-${variant}.js?${Math.random()}`;
            scr.onload = res;
            scr.onerror = () => {
              alert("Failed to load variant!");
            };
            document.body.appendChild(scr);
          });
          const libav = await LibAV.LibAV();

          // Load the file
          const file = await new Promise((res) => {
            main.innerHTML = "";
            const label = dce("label");
            label.innerHTML = "File:&nbsp;";
            label.htmlFor = "load-file";
            main.appendChild(label);
            const picker = dce("input");
            picker.type = "file";
            picker.id = "load-file";
            main.appendChild(picker);

            picker.focus();

            picker.onchange = () => {
              if (picker.files.length > 0) res(picker.files[0]);
            };

            fetchFile("videos/house-of-the-dragon-4k-3840x2160.mov").then(
              (blob) => {
                // fetchFile("videos/house-of-the-dragon-320x240.mov").then((blob) => {
                res(blob);
              }
            );
          });
          main.innerHTML = "Loading...";

          let frameCounter = 0;

          // Initial read
          await libav.mkreadaheadfile("input", file);
          const [fmt_ctx, streams] = await libav.ff_init_demuxer_file("input");

          // Find the video stream (FIXME: eventually audio stream too?)
          let videoIdx = -1;
          for (let i = 0; i < streams.length; i++) {
            if (streams[i].codec_type === libav.AVMEDIA_TYPE_VIDEO) {
              videoIdx = i;
              break;
            }
          }
          if (videoIdx < 0) {
            main.innerHTML = "Error! Couldn't find video stream!";
            return;
          }

          const videoStream = streams[videoIdx];

          const codecparPtr = videoStream.codecpar;
          const width = await libav.AVCodecParameters_width(codecparPtr);
          const height = await libav.AVCodecParameters_height(codecparPtr);
          console.log(`${width}x${height}`);
          console.log(videoStream);

          // Set up the "player"
          main.innerHTML = "";
          //   const durationBox = dce("div");
          //   durationBox.innerHTML = `0/${videoStream.duration}`;
          //   main.appendChild(durationBox);
          const statsBox = dce("div");
          statsBox.innerHTML = "&nbsp;";
          main.appendChild(statsBox);
          const renderChk = dce("input");
          renderChk.style.display = "none";
          renderChk.type = "checkbox";
          renderChk.checked = true;
          main.appendChild(renderChk);
          const canvas = dce("canvas");
          canvas.style.display = "block";
          canvas.width = width;
          canvas.height = height;
          canvas.style.width = `${width / devicePixelRatio}px`;
          canvas.style.height = `${height / devicePixelRatio}px`;
          main.appendChild(canvas);
          const cctx = canvas.getContext("2d");
          const seeker = dce("input");
          seeker.type = "range";
          seeker.min = 0;
          seeker.max = Math.ceil(videoStream.duration * 10);
          seeker.style.visibility = "hidden";
          main.appendChild(seeker);
          let seekerWakeup = null;

          // Prepare to seek
          let seeked = false;
          seeker.oninput = async () => {
            let frameCounter = 0;
            const ts =
              ((seeker.value / 10) * videoStream.time_base_den) /
              videoStream.time_base_num;
            const ret = await libav.avformat_seek_file_max(
              fmt_ctx,
              videoIdx,
              ts,
              0
            );
            seeked = true;
            if (seekerWakeup) {
              const w = seekerWakeup;
              seekerWakeup = null;
              w();
            }
          };

          // Initialize the decoder
          const [, c, pkt, frame] = await libav.ff_init_decoder(
            videoStream.codec_id,
            videoStream.codecpar
          );

          // Prepare to initialize the scaler (for pixel format)
          let inW = -1,
            inH = -1,
            inF = -1;
          let sctx = null;
          const sinFrame = await libav.av_frame_alloc();
          const soutFrame = await libav.av_frame_alloc();

          // Prepare for stats
          const stats = [];

          const id = cctx.createImageData(width, height);

          const [buffersrc_ctx, buffersink_ctx] = await init_filters(
            libav,
            width,
            height,
            "yuv422p10le",
            // "1/25"
            "1/12800"
          );

          // And read
          while (true) {
            console.time("loop");
            // Read some packets
            console.time("ff_read_multi");
            const [res, packets] = await libav.ff_read_multi(
              fmt_ctx,
              pkt,
              null,
              {
                limit: 1,
              }
            );
            console.timeEnd("ff_read_multi");

            /* And decode them. We decode them one-by-one for stats
             * purposes, but obviously would do several at a time for
             * better performance. */
            const vPackets = packets[videoIdx];
            for (let vIdx = 0; vPackets && vIdx < vPackets.length; vIdx++) {
              const vPacket = vPackets[vIdx];
              if (seeked) break;

              const stat = {
                start: performance.now() / 1000,
                frames: 0,
                pts: 0,
                end: 0,
              };
              stats.push(stat);
              const early = stat.start - 2;
              while (stats[0].start < early) stats.shift();

              // Decode it
              console.time("ff_decode_multi");
              const decodedFrames = await libav.ff_decode_multi(
                c,
                pkt,
                frame,
                [vPacket],
                res === libav.AVERROR_EOF && vIdx === vPackets.length - 1
              );
              console.timeEnd("ff_decode_multi");

              console.time("ff_filter_multi");
              const frames = await libav.ff_filter_multi(
                buffersrc_ctx,
                buffersink_ctx,
                frame,
                decodedFrames,
                res === libav.AVERROR_EOF && vIdx === vPackets.length - 1
              );
              console.timeEnd("ff_filter_multi");

              // Display any frames here
              for (let frame of frames) {
                frameCounter++;
                const pts = frame.pts;

                // Convert from libav planes to ImageData
                console.time("convert libav planes to ImageData");
                console.time("convert loop");
                {
                  let idx = 0;
                  const plane = frame.data[0];
                  for (const line of plane) {
                    id.data.set(line, idx);
                    idx += frame.width * 4;
                  }
                }
                console.timeEnd("convert loop");
                console.time("id.data.set");
                id.data.set(frame.data[0]);
                console.timeEnd("id.data.set");
                console.timeEnd("convert libav planes to ImageData");

                // Display it
                console.time("createImageBitmap");
                const ib = await createImageBitmap(id);
                console.timeEnd("createImageBitmap");

                console.time("clearRect");
                cctx.clearRect(0, 0, width, height);
                console.timeEnd("clearRect");

                console.time("drawImage");
                cctx.drawImage(ib, 0, 0, width, height);
                console.timeEnd("drawImage");

                // And show it
                const start =
                  (pts * videoStream.time_base_num) / videoStream.time_base_den;
                //   durationBox.innerText = `${t.toFixed(2)}/${
                //     videoStream.duration
                //   }`;
                seeker.value = start * 10;
              }

              // And figure out stats
              stat.end = performance.now() / 1000;
              stat.frames = frames.length;
              if (frames.length) {
                stat.pts = frames[frames.length - 1].pts;
              } else {
                stats.pop();
              }

              if (stats.length) {
                const first = stats[0];
                const secondLast =
                  stats[stats.length > 1 ? stats.length - 2 : 0];
                const last = stats[stats.length - 1];
                const fps =
                  stats.map((x) => x.frames).reduce((x, y) => x + y, 0) /
                  (last.end - first.start);

                const frameTime =
                  (last.pts * videoStream.time_base_num) /
                  videoStream.time_base_den;
                const previousFrameTime =
                  (secondLast.pts * videoStream.time_base_num) /
                  videoStream.time_base_den;

                const framesPlayed = frameCounter;

                const frameDuration = frameTime - previousFrameTime;
                const timePlayed = frameTime + frameDuration;
                const sourceFPS = framesPlayed / timePlayed;

                // console.log(
                //   `frameTime = ${frameTime.toFixed(
                //     2
                //   )}, previousFrameTime = ${previousFrameTime.toFixed(
                //     2
                //   )}, frameDuration = ${frameDuration.toFixed(
                //     2
                //   )} timePlayed = ${timePlayed.toFixed(
                //     2
                //   )}, framesPlayed = ${framesPlayed.toFixed(
                //     2
                //   )}, sourceFPS = ${sourceFPS.toFixed(2)}`
                // );

                // Duration of track in seconds, frame count
                const xrt =
                  ((last.pts - first.pts) * videoStream.time_base_num) /
                  videoStream.time_base_den /
                  (last.end - first.start);

                statsBox.innerText = `
                      ${width} x ${height} @ ${sourceFPS.toFixed(2)} FPS
                      ${fps.toFixed(2)} FPS Playback \n${xrt.toFixed(
                  2
                )}x Real-time`;
              }
            }

            console.timeEnd("loop");
            console.log("\n\n\n\n\n");

            if (seeked) {
              seeked = false;
              continue;
            }

            if (res === libav.AVERROR_EOF) {
              // Await seeking elsewhere
              await new Promise((res) => {
                seekerWakeup = res;
              });
            }
          }
        } catch (ex) {
          alert(ex + "");
        }
      })();

      // Define an asynchronous function to initialize filters using the libav library.
      async function init_filters(libav, width, height, pix_fmt, time_base) {
        // Set the description for the filter graph. In this case, it's a format filter to convert frames to RGB24.
        const filters_descr = "format=rgba";

        // Get the buffer source filter from the libav library, which will be used to feed frames into the filter graph.
        const buffersrc = await libav.avfilter_get_by_name("buffer");

        // Get the buffer sink filter from the libav library, which will be used to extract frames from the filter graph.
        const buffersink = await libav.avfilter_get_by_name("buffersink");

        // Allocate an AVFilterInOut structure for outputs, which will hold the linked list of input pads.
        const outputs = await libav.avfilter_inout_alloc();

        // Allocate an AVFilterInOut structure for inputs, which will hold the linked list of output pads.
        const inputs = await libav.avfilter_inout_alloc();

        // Allocate a filter graph using libav.
        const filter_graph = await libav.avfilter_graph_alloc();

        // Check if any of the crucial structures failed to allocate and throw an error if so.
        if (!outputs || !inputs || !filter_graph) {
          throw new Error();
        }

        // Create a buffer source context in the filter graph.
        const description = `video_size=${width}x${height}:pix_fmt=${pix_fmt}:time_base=${time_base}`;
        console.log(description);
        const buffersrc_ctx = await libav.avfilter_graph_create_filter_js(
          buffersrc,
          "in",
          description,
          null,
          filter_graph
        );

        // Create a buffer sink context in the filter graph. No specific options are set here.
        const buffersink_ctx = await libav.avfilter_graph_create_filter_js(
          buffersink,
          "out",
          null,
          null,
          filter_graph
        );

        // Duplicate the strings "in" and "out" for use in setting up the AVFilterInOut structures.
        const strdupIn = await libav.av_strdup("in");
        const strdupOut = await libav.av_strdup("out");

        // Check for failures in creating the buffer contexts or duplicating strings and throw errors if necessary.
        if (buffersrc_ctx === 0)
          throw new Error("Cannot create video buffer source");
        if (buffersink_ctx === 0)
          throw new Error("Cannot create video buffer sink");
        if (strdupIn === 0 || strdupOut === 0)
          throw new Error("Failed to strdup");

        // // Attempt to set the pixel format on the buffer sink context, though this seems misplaced as the format should be set by the format filter.
        // const format = await libav.av_opt_set(
        //   buffersink_ctx,
        //   "format",
        //   "rgb24",
        //   libav.AV_OPT_SEARCH_CHILDREN
        // );

        // Set the name and filter context for the outputs AVFilterInOut structure.
        await libav.AVFilterInOut_name_s(outputs, strdupIn);
        await libav.AVFilterInOut_filter_ctx_s(outputs, buffersrc_ctx);
        await libav.AVFilterInOut_pad_idx_s(outputs, 0);
        await libav.AVFilterInOut_next_s(outputs, 0);

        await libav.AVFilterInOut_name_s(inputs, strdupOut);
        await libav.AVFilterInOut_filter_ctx_s(inputs, buffersink_ctx);
        await libav.AVFilterInOut_pad_idx_s(inputs, 0);
        await libav.AVFilterInOut_next_s(inputs, 0);

        // Parse the filter graph based on the filter description string.
        const parseResult = await libav.avfilter_graph_parse(
          filter_graph,
          filters_descr,
          inputs,
          outputs,
          0
        );

        // Check for failure in parsing the filter graph and throw an error if necessary.
        if (parseResult < 0) {
          throw new Error("Failed to initialize filters");
        }

        // Configure the filter graph.
        const graphConfigResult = await libav.avfilter_graph_config(
          filter_graph,
          0
        );

        // Check for failure in configuring the filter graph and throw an error if necessary.
        if (graphConfigResult < 0) {
          throw new Error("Failed to configure filtergraph");
        }

        // Return the buffer source and sink contexts for further use.
        return [buffersrc_ctx, buffersink_ctx];
      }
    </script>
  </body>
</html>
